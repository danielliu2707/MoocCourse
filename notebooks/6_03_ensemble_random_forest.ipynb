{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests\n",
    "\n",
    "In this notebook, we will present the random forest models and show the\n",
    "differences with the bagging ensembles.\n",
    "\n",
    "Random forests are a popular model in machine learning. They are a\n",
    "modification of the bagging algorithm. In bagging, any classifier or regressor\n",
    "can be used. In random forests, the base classifier or regressor is always a\n",
    "decision tree.\n",
    "\n",
    "Random forests have another particularity: when training a tree, the search\n",
    "for the best split is done only on a subset of the original features taken at\n",
    "random. The random subsets are different for each split node. The goal is to\n",
    "inject additional randomization into the learning procedure to try to\n",
    "decorrelate the prediction errors of the individual trees.\n",
    "\n",
    "Therefore, random forests are using **randomization on both axes of the data\n",
    "matrix**:\n",
    "\n",
    "- by **bootstrapping samples** for **each tree** in the forest;\n",
    "- randomly selecting a **subset of features** at **each node** of the tree.\n",
    "\n",
    "## A look at random forests\n",
    "\n",
    "We will illustrate the usage of a random forest classifier on the adult census\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "adult_census = pd.read_csv(\"../datasets/adult-census.csv\")\n",
    "target_name = \"class\"\n",
    "data = adult_census.drop(columns=[target_name, \"education-num\"])\n",
    "target = adult_census[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99dbd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass      education       marital-status          occupation  \\\n",
       "0   25     Private           11th        Never-married   Machine-op-inspct   \n",
       "1   38     Private        HS-grad   Married-civ-spouse     Farming-fishing   \n",
       "2   28   Local-gov     Assoc-acdm   Married-civ-spouse     Protective-serv   \n",
       "3   44     Private   Some-college   Married-civ-spouse   Machine-op-inspct   \n",
       "4   18           ?   Some-college        Never-married                   ?   \n",
       "\n",
       "  relationship    race      sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0    Own-child   Black     Male             0             0              40   \n",
       "1      Husband   White     Male             0             0              50   \n",
       "2      Husband   White     Male             0             0              40   \n",
       "3      Husband   Black     Male          7688             0              40   \n",
       "4    Own-child   White   Female             0             0              30   \n",
       "\n",
       "   native-country  \n",
       "0   United-States  \n",
       "1   United-States  \n",
       "2   United-States  \n",
       "3   United-States  \n",
       "4   United-States  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d11466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The adult census contains some categorical data and we encode the categorical\n",
    "features using an `OrdinalEncoder` since tree-based models can work very\n",
    "efficiently with such a naive representation of categorical variables.\n",
    "\n",
    "Since there are rare categories in this dataset we need to specifically encode\n",
    "unknown categories at prediction time in order to be able to use\n",
    "cross-validation. Otherwise some rare categories could only be present on the\n",
    "validation side of the cross-validation split and the `OrdinalEncoder` would\n",
    "raise an error when calling its `transform` method with the data points of the\n",
    "validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7f30b",
   "metadata": {},
   "source": [
    "\n",
    "We will first give a simple example where we will train a single decision tree\n",
    "classifier and check its generalization performance via cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190a9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier: 0.819 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "numerical_column_selector = selector(dtype_exclude=object)\n",
    "categorical_column_selector = selector(dtype_include=object)\n",
    "numerical_columns = numerical_column_selector(data)\n",
    "categorical_columns = categorical_column_selector(data)\n",
    "\n",
    "categorical_preprocessor = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"categorical-preprocessor\", categorical_preprocessor, categorical_columns)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "decision_tree = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"rf\", DecisionTreeClassifier(random_state=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_results = cross_validate(decision_tree, data, target)\n",
    "scores = cv_results['test_score']\n",
    "print(\n",
    "    \"Decision tree classifier: \"\n",
    "    f\"{scores.mean():.3f} ± {scores.std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Similarly to what was done in the previous notebook, we construct a\n",
    "`BaggingClassifier` with a decision tree classifier as base model. In\n",
    "addition, we need to specify how many models do we want to combine. Note that\n",
    "we also need to preprocess the data and thus use a scikit-learn pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de5d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged decision tree classifier: 0.846 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagged_tree = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"bagged_tree\", BaggingClassifier(\n",
    "            estimator=DecisionTreeClassifier(random_state=0), n_estimators=50, random_state=0, n_jobs=-1\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_results = cross_validate(bagged_tree, data, target)\n",
    "scores = cv_results['test_score']\n",
    "print(\n",
    "    \"Bagged decision tree classifier: \"\n",
    "    f\"{scores.mean():.3f} ± {scores.std():.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the generalization performance of the bagged trees is already much\n",
    "better than the performance of a single tree.\n",
    "\n",
    "Now, we will use a random forest. You will observe that we do not need to\n",
    "specify any `estimator` because the estimator is forced to be a decision tree.\n",
    "Thus, we just specify the desired number of trees in the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fad27af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged decision tree classifier: 0.851 ± 0.003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomforest = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"randomforest\", RandomForestClassifier(n_estimators=50, n_jobs=-1, random_state=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_results = cross_validate(randomforest, data, target)\n",
    "scores = cv_results['test_score']\n",
    "print(\n",
    "    \"Bagged decision tree classifier: \"\n",
    "    f\"{scores.mean():.3f} ± {scores.std():.3f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the random forest is performing slightly better than the bagged\n",
    "trees possibly due to the randomized selection of the features which\n",
    "decorrelates the prediction errors of individual trees and as a consequence\n",
    "make the averaging step more efficient at reducing overfitting.\n",
    "\n",
    "## Details about default hyperparameters\n",
    "\n",
    "For random forests, it is possible to control the amount of randomness for\n",
    "each split by setting the value of `max_features` hyperparameter:\n",
    "\n",
    "- `max_features=0.5` means that 50% of the features are considered at each\n",
    "  split;\n",
    "- `max_features=1.0` means that all features are considered at each split\n",
    "  which effectively disables feature subsampling.\n",
    "\n",
    "By default, `RandomForestRegressor` disables feature subsampling while\n",
    "`RandomForestClassifier` uses `max_features=np.sqrt(n_features)`. These\n",
    "default values reflect good practices given in the scientific literature.\n",
    "\n",
    "However, `max_features` is one of the hyperparameters to consider when tuning\n",
    "a random forest:\n",
    "- too much randomness in the trees can lead to underfitted base models and can\n",
    "  be detrimental for the ensemble as a whole,\n",
    "- too few randomness in the trees leads to more correlation of the prediction\n",
    "  errors and as a result reduce the benefits of the averaging step in terms of\n",
    "  overfitting control.\n",
    "\n",
    "In scikit-learn, the bagging classes also expose a `max_features` parameter.\n",
    "However, `BaggingClassifier` and `BaggingRegressor` are agnostic with respect\n",
    "to their base model and therefore random feature subsampling can only happen\n",
    "once before fitting each base model instead of several times per base model as\n",
    "is the case when adding splits to a given tree.\n",
    "\n",
    "We summarize these details in the following table:\n",
    "\n",
    "| Ensemble model class     | Base model class          | Default value for `max_features`   | Features subsampling strategy |\n",
    "|--------------------------|---------------------------|------------------------------------|-------------------------------|\n",
    "| `BaggingClassifier`      | User specified (flexible) | `n_features` (no&nbsp;subsampling) | Model level                   |\n",
    "| `RandomForestClassifier` | `DecisionTreeClassifier`  | `sqrt(n_features)`                 | Tree node level               |\n",
    "| `BaggingRegressor`       | User specified (flexible) | `n_features` (no&nbsp;subsampling) | Model level                   |\n",
    "| `RandomForestRegressor`  | `DecisionTreeRegressor`   | `n_features` (no&nbsp;subsampling) | Tree node level               |"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "mlmooc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
